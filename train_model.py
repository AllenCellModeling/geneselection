import argparse

import importlib
import numpy as np

import os

import torch
import torch.optim
import torch.nn

import datetime
import json

import socket

from ignite.engine import Engine, Events

from ignite.handlers import Timer

from hpaclassificationnhb.utils import model_utils
import hpaclassificationnhb.losses as losses

from geneselection.utils import str2bool




if __name__ == "__main__":

    parser = argparse.ArgumentParser()

    parser.add_argument("--gpu_ids", nargs="+", type=int, default=0, help="gpu id")
    parser.add_argument("--myseed", type=int, default=0, help="random seed")

    parser.add_argument("--lr", type=float, default=0.0005, help="learning rate")
    parser.add_argument(
        "--optimizer_name",
        default="Adam",
        help="type of optimizer, can be {adam, RMSprop}",
    )
    parser.add_argument(
        "--optimizer_kwargs",
        type=json.loads,
        default={},
        help="kwargs for the optimizer",
    )
    parser.add_argument(
        "--model_name", default="BaseConvNet", help="name of the classifier module"
    )
    parser.add_argument(
        "--model_kwargs", type=json.loads, default={}, help="kwargs for the classifier"
    )
    parser.add_argument(
        "--data_provider_name", default="ModelDataProviders", help="Dataprovider object"
    )
    parser.add_argument(
        "--data_provider_kwargs",
        type=json.loads,
        default={},
        help="kwargs for the data provider",
    )
    parser.add_argument(
        "--crit_loss_name",
        default="torch.nn.MSELoss",
        help="Loss function for image reconstruction",
    )
    parser.add_argument(
        "--crit_loss_kwargs",
        type=json.loads,
        default={},
        help="kwargs for the loss function",
    )
   
    parser.add_argument("--batch_size", type=int, default=32, help="batch size")
    parser.add_argument(
        "--n_epochs", type=int, default=250, help="total number of epochs"
    )
    parser.add_argument("--save_dir", type=str, default=None, help="save dir")
    parser.add_argument(
        "--save_parent",
        type=str,
        default=None,
        help='parent save directory to save with autogenerated working directory (mutually exclusive to "--save_dir")',
    )
    parser.add_argument(
        "--save_progress_iter",
        type=int,
        default=1,
        help="number of iterations between saving progress",
    )
    parser.add_argument(
        "--save_state_iter",
        type=int,
        default=10,
        help="number of iterations between saving model state",
    )

    parser.add_argument(
        "--overwrite_args", default=False, type=str2bool, help="Overwrite argsions file"
    )
    parser.add_argument(
        "--n_dat",
        default=None,
        type=int,
        help="Number of data to use in the dataprovider. None = use all data.",
    )

    parser.add_argument(
        "--use_scheduler",
        default=False,
        type=str2bool,
        help="Use a learning rate scheduler",
    )

    args = parser.parse_args()

    # ARGUMENT SETTING/CHECKING
    if (args.save_parent is not None) and (args.save_dir is not None):
        raise ValueError(
            "--save_dir and --save_parent are both set. Please choose one or the other."
        )

    the_time = datetime.datetime.now().strftime("%Y-%m-%d-%H:%M:%S")
    if args.save_parent is not None:
        args.save_dir = os.path.join(args.save_parent, the_time)

    args.the_time = the_time
    args.save_parent = args.save_dir
    args.hostname = socket.gethostname()

    if not os.path.exists(args.save_dir):
        os.makedirs(args.save_dir)

    save_path = "{0}/classifier.pth".format(args.save_dir)

    # SET CUDA DEVICES
    os.environ["CUDA_VISIBLE_DEVICES"] = ",".join([str(ID) for ID in args.gpu_ids])
    args.gpu_ids = list(range(0, len(args.gpu_ids)))

    args_path = "{0}/args.json".format(args.save_dir)
    args = model_utils.save_load_args(args, args_path)

    print(args)
    # DONE ARGUMENT SETTING/CHECKING

    # SET SEEDS
    torch.manual_seed(args.myseed)
    torch.cuda.manual_seed(args.myseed)
    np.random.seed(args.myseed)

    # IMPORT MODEL
    print(args.model_kwargs)
    model_module = importlib.import_module(
        "hpaclassificationnhb.models." + args.model_name
    )
    model = model_module.Model(**args.model_kwargs, gpu_ids=args.gpu_ids)
    model = model.cuda(args.gpu_ids[0])

    # IMPORT OPTIMIZER
    optimizer_constructor = eval("torch.optim." + args.optimizer_name)
    optimizer = optimizer_constructor(
        model.parameters(), lr=args.lr, **args.optimizer_kwargs
    )

    if os.path.exists(save_path):
        model_utils.load_state(model, optimizer, save_path, args.gpu_ids[0])

    # IMPORT DATAPROVIDER
    dataprovider_module = importlib.import_module(
        "hpaclassificationnhb.data_providers." + args.data_provider_name
    )

    dp = dataprovider_module.make_dp_train(
        data_dir="./data",
        batch_size=args.batch_size,
        n_dat=args.n_dat,
        **args.data_provider_kwargs,
    )

    train_loader, val_loader = dp.dataloaders["train"], dp.dataloaders["validation"]

    # IMPORT LOSS FUNCTION
    losses

    if args.crit_weight_classes:
        class_frequencies = np.vstack(
            list(train_loader.dataset.df["Target"].values)
        ).sum(axis=0)
        class_frequencies = torch.tensor(class_frequencies)
        args.crit_loss_kwargs["class_frequencies"] = class_frequencies

    crit_loss_constructor = eval(args.crit_loss_name)
    crit_loss = crit_loss_constructor(**args.crit_loss_kwargs)

    scheduler = None
    if args.use_scheduler:
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, "max", factor=0.1, patience=10, verbose=True, threshold=0.0001
        )

    # RUN
    trainer(
        model=model,
        optimizer=optimizer,
        crit_loss=crit_loss,
        train_loader=train_loader,
        val_loader=val_loader,
        n_epochs=args.n_epochs,
        gpu_ids=args.gpu_ids,
        save_dir=args.save_dir,
        save_progress_iter=args.save_progress_iter,
        save_state_iter=args.save_state_iter,
        scheduler=scheduler,
        print_prefix=the_time + " ",
    )

